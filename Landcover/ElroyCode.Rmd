---
title: "Malurus Pop Gen"
author: "Elroy Au"
date: "05/09/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

### ================================== ###
### Samples Distribution Map           ###
### ================================== ###

```Generate a map of the distribution of M. assimilis tissue samples across Australia coded by collection date```

```{r}

# load libraries
library(oz)
library(readxl)

# load dataset
samples <- read_excel("Samples-Geo-Date.xlsx")
```

```{r}

# set the latitudes and longitudes of points  
lat1 <- samples$`Latitude-1`        
lat2 <- samples$`Latitude-2`       
lat3 <- samples$`Latitude-3`        
lat4 <- samples$`Latitude-4`        
lat5 <- samples$`Latitude-5`        
lat6 <- samples$`Latitude-6`       
lat7 <- samples$`Latitude-7`
long1 <- samples$`Longitude-1`
long2 <- samples$`Longitude-2`
long3 <- samples$`Longitude-3`
long4 <- samples$`Longitude-4`
long5 <- samples$`Longitude-5`
long6 <- samples$`Longitude-6`
long7 <- samples$`Longitude-7`
```

```{r}

# plot Australia 

oz()

# plot points 

points(long1,lat1, col = "#85C1E9", bg = "#85C1E9", pch = 24)   
points(long2,lat2, col = "#5DADE2", bg = "#5DADE2", pch = 24)
points(long3,lat3, col = "#3498DB", bg = "#3498DB", pch = 24)
points(long4,lat4, col = "#2E86C1", bg = "#2E86C1", pch = 24)
points(long5,lat5, col = "#2874A6", bg = "#2874A6", pch = 24)
points(long6,lat6, col = "#21618C", bg = "#21618C", pch = 24)
points(long7,lat7, col = "#1B4F72", bg = "#1B4F72", pch = 24)
```

### ================================== ###
### SNP Parameters                     ###
### ================================== ###

```Plotting parameters calculated for SNP filtering including: Coverage Depth,
Individual Missingness, Average Site Depth and Site Missingness```

### Coverage Depth 

```{r}

# load libraries
library(ggplot2)
library(readxl)

# load dataset 
# this is an excel file containing the coverage of each individual sample as 
# estimated using SamTools 

coverage <- read_excel("coverage.xlsx")
```

```{r}

# plot a histogram of the distribution of sample coverage using ggplot2

ggplot (coverage, aes(coverage$`Coverage Depth`)) + geom_histogram(breaks=seq(0,8, by =1), col="grey1", aes(fill=..count..)) + scale_fill_gradient("Count", high = "paleturquoise4", low = "paleturquoise1") + labs(x="Coverage Depth", y = "Frequency") + theme_bw()
```

### Average Site Depth 

```{r}

# load libraries
library(ggplot2)
library(readxl)

# load dataset 
# this is an excel file containing the average depth of 100,000 random sites
# trimmed of sites with average depth >8 as these sites drag the histogram out
# such that the resolution is unreadable 
meansitedepth <- read_excel("mean-site-depth-trimmed-2.xlsx")
```

```{r}

# set the variable sitedepth 
sitedepth <- meansitedepth$`Mean Site Depth`

# create a histogram 
hist(sitedepth, breaks=100, main = "Average Site Depth",    
     xlab = "Average Site Depth") 

# calculate the average depth
mean <- mean(sitedepth) 

# calculate the standard deviation
SD <- sd(sitedepth)  

# calculate 3 standard deviations
sdevs <- SD * 3  

# set the cutoff for average site depth as anything above this are usually 
# sequencing artefacts or paralogs 
cutoff <- sdevs + mean

# add lines representing the average site depth and cutoff site depth to the 
# histogram
abline(v = mean, col = "red", lwd = 2)                      
abline(v = cutoff, col = "blue", lwd = 2)
```

### Individual Missingness             

```{r}

# load libraries
library(ggplot2)    
library(readxl)

# load dataset
# this is an excel file containing the individual missingness values for all
# samples across all 25 chromosomes 
missingness <- read_excel("missingness.xlsx")
```

```{r}

# plot missingness
ggplot (missingness, aes(missingness)) + geom_histogram(breaks=seq(0,0.8, by =0.1), col="grey1", aes(fill=..count..)) + scale_fill_gradient("Count", high = "red4", low = "palevioletred2") + labs(x="Individual Missingness", y = "Frequency") + theme_bw()
```

### Site Missingness 

```{r}

# load libraries 
library(ggplot2)    
library(readxl)

# load dataset
# this is an excel file containing the missingness of 100,000 sites across
# all 25 chromosomes
sitemissingness <- read_excel("site-missingness.xlsx")
```

```{r}

# plot site missingness 

ggplot (sitemissingness, aes(sitemissingness$`site-missingness`)) + geom_histogram(breaks=seq(0,1, by =0.1), col="grey1", aes(fill=..count..)) + scale_fill_gradient("Count", high = "goldenrod2", low = "lightgoldenrod2") + labs(x="Site Missingness", y = "Frequency") + theme_bw()
```

### ================================== ###
### Data Analysis                      ###
### ================================== ###

### ================================== ###
### PCA                                ###
### ================================== ###

```{r}

# load libraries

library(ggplot2)
library(readxl) 
library(RcppCNPy)     # for reading .npy (NUMPY) files
library(sf) 

# load datasets
# PCA.cov.npy is the covariance matrix without outlier individuals filtered, n=133
# PCA.filtered.cov.npy is the covariance matrix with outlier individuals filtered, # n = 119
# PCA.climate.cov.npy is the covariance matrix with individuals from PCA.filtered.cov.npy who are missing climate data removed
covmatrix <- npyLoad("PCA.cov.npy")  
covmatrixfiltered <- npyLoad("PCA.filtered.cov.npy")
climcovmatrix <- npyLoad("PCA.climate.cov.npy")

# calculate eigenvalues
Eigenvalues <- eigen(covmatrixfiltered)$values         
# calculate eigenvectors
Eigenvectors <- eigen(covmatrixfiltered)$vectors  
# calculate the principal components using a matrix multiplication 
PC <- as.matrix(covmatrixfiltered) %*% Eigenvectors
# transpose the data in order to get the loading of the variables for each principal component 
PCs <- t(PC)

# calculate the proportions of the variation explained by the various components
print(round(Eigenvalues/sum(Eigenvalues) * 100, digits = 2))
round(cumsum(Eigenvalues)/sum(Eigenvalues) * 100, digits = 2)

# take the principal component scores for individuals to create the PCA plot
PC1 <- PC[,1]
PC2 <- PC[,2]
PC3 <- PC[,3]

# transform into a dataframe and copied into an excel spreadsheet to form the
# principal component values in PCA-metadata.xlsx
PCA <- data.frame(PC1, PC2, PC3)
```

```{r}

# create a biplot by hand
# load libraries
library(readxl)

# load dataset 
biplot.pca.metadata <- read_excel("Biplot Metadata.xlsx")
biplot.metadata <- read_excel("PCA-metadata.xlsx")

# set pch and colour groups (grouped by geography: NSW, NT, QLD, SA, VIC, WA, NA)
pch.group <- c(rep(21, times=10), rep(22, times=10), rep(23, times=10), rep(24, times=43), rep(3, times=1), rep(25, times=43), rep(4, times=2))

# red = NSW, gold = NT, green = QLD, blue = SA, black = VIC, pink = WA, black X = N.A
col.group <- c(rep("red", times=10), rep("gold", times=10), rep("green", times=10), rep("skyblue2", times=43), rep("black", times=1), rep("violet", times=43), rep("grey", times=2))

# plot the individuals in principal component space grouped by their shape and colour for state of collection 
plot(x=biplot.pca.metadata$PC1, y=biplot.pca.metadata$PC2, xlab="PC1 (3.18%)", ylab="PC2 (1.23%)", xlim=c(-1.0,1.0),ylim=c(-0.6,0.6), pch=pch.group, col="black", bg=col.group, cex=2, las=1, asp=1)

# add horizontal and vertical axes at zero 
abline(v=0, lty=2, col="grey50")
abline(h=0, lty=2, col="grey50")

# set the x and y co-ordinates of the variables, which are equivalent to
# the loading scores of the variables (i.e. the individual samples)
# these will form the arrows on the bi-lot and were created by transposing the 
# principal component data made above (check PCs)
l.x <- PCs[,1]
l.y <- PCs[,2]
arrows(x0=0, x1=l.x, y0=0, y1=l.y, col="red", length = 0.1, lwd = 1.5)

# set text labels 
l.pos <- l.y
lo <- which(l.y < 0)
hi <- which(l.y > 0)
l.pos <- replace(l.pos, lo, "1")
l.pos <- replace(l.pos, hi, "3")
text(l.x, l.y, labels=biplot.pca.metadata$`SAMPLE ID`, col="red", pos=l.pos)
```

```{r}

# load the new data
PCA <- read_excel("PCA-metadata.xlsx")

# plot principal components with the collection date and geographic
# location (state) metadata 
ggplot(PCA, aes(x=PC1, y=PC2)) + geom_point(aes(shape = Period, color = STATE), position = "jitter", size = 2.5) + scale_shape_manual(values = c(3, 4, 8, 15, 17, 18, 19, 25)) + theme_bw() 

# plot principal components with the collection date and indvidual 
# missingness metadata
ggplot (PCA, aes(x=PC1, y=PC2)) + geom_point(aes(shape = Period, color = MISSINGNESS), position = "jitter", size = 2.5) + scale_shape_manual(values = c(3, 4, 8, 15, 17, 18, 19, 25)) + scale_color_continuous(high = "black", low = "turquoise2") + theme_bw() 

# plot samples by latitude and longitude on a scale of principal 
# componentvalues

australia <- st_read("australia.shp")
a <- ggplot() + geom_sf(data = australia, color = "black", fill = "white")
a + geom_point(data=PCA, aes(x=LONGITUDE, y=LATITUDE, color = PC1), size = 2.5) + scale_color_gradient2()
```

### ================================== ###
### Linear Regression                  ###
### ================================== ###

```{r}

# load libraries

library(ggplot2)   
library(readxl)     
library(tidyverse)  # for correlation matrix

# load the new data
PCA <- read_excel("PCA-metadata.xlsx")

# linear regression model of PC1 values and individual missingness 
regression <- lm(PC1~MISSINGNESS, data = PCA)

summary(regression) 

# calculate the Pearson's correlation coefficient 
cPC1 <- PCA$PC1
cMiss <- PCA$MISSINGNESS
cor.test(cMiss, cPC1, method=c("pearson")) 

# create a correlation matrix 
cor(PCA %>% select(PC1, PC2, Year, LATITUDE, LONGITUDE), use="pairwise.complete.obs")

# plot a linear regression 
ggplot(PCA, aes(y=PC1, x=MISSINGNESS)) + geom_point() + geom_smooth(method="lm") + theme_bw()
```

### ================================== ###
### NGSadmix - ADMIXTURE               ###
### ================================== ###

```{r}

# load libraries
library(RColorBrewer)

# load the data 

pop <- read.table("Admix-Pop-Data.txt", fill = TRUE, header = FALSE)

q2 <- read.table("admix.2.txt", fill = TRUE, header = FALSE)

q3 <- read.table("admix.3.txt", fill = TRUE, header = FALSE)

q4 <- read.table("admix.4.txt", fill = TRUE, header = FALSE)

q5 <- read.table("admix.5.txt", fill = TRUE, header = FALSE)

q6 <- read.table("admix.6.txt", fill = TRUE, header = FALSE)


# order according to population
ord <- order (pop[,2])

# plot admixture for k
barplot(t(q2)[,ord],col=2:10, space=0, border=NA, xlab="Individuals", ylab="AdmixtureProportions(K=2)") 

# plot admixture for k using color brewer scheme 
barplot(t(q3)[,ord],col=brewer.pal(n=3, name="RdBu"),   
        space=0, border=NA, xlab="Individuals",         
        ylab="Admixture Proportions (K=3)")

# add individual population labels 
text(tapply(1:nrow(pop), pop[ord,2], mean),-0.05, unique(pop[ord,2]),xpd=T)  

# add lines between each individual and population
abline(v=cumsum(sapply(unique(pop[ord,1]), function(x){sum(pop[ord,1]==x)})), col="white",lwd=0.5)

abline(v=cumsum(sapply(unique(pop[ord,2]), function(x){sum(pop[ord,2]==x)})), col=1,lwd=2) 
```

### ================================== ###
### ADMIXTURE SCATTER PLOTS            ###
### ================================== ###

```{r}

# load libraries

library(ggplot2)       
library(ggrepel)        
library(scatterpie)     
library(sf) 
library(readxl)

admixture <- read_excel("admix-metadata.xlsx")

# load shapefile of Australia

australia <- st_read("australia.shp")

# create a vector plot of Australia 
a <- ggplot() + geom_sf(data = australia, color = "black", fill = "white") 

# K = 2

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K2.1
K2 <- admixture$K2.2

admixdata2 <- data.frame(Lat,Long,K1,K2)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata2, cols = c("K1", "K2")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()

# K = 3

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K3.1
K2 <- admixture$K3.2
K3 <- admixture$K3.3

admixdata3 <- data.frame(Lat,Long,K1,K2,K3)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata3, cols = c("K1", "K2", "K3")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()

# K = 4

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K4.1
K2 <- admixture$K4.2
K3 <- admixture$K4.3
K4 <- admixture$K4.4

admixdata4 <- data.frame(Lat,Long,K1,K2,K3,K4)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata4, cols = c("K1", "K2", "K3", "K4")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()

# K = 5

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K5.1
K2 <- admixture$K5.2
K3 <- admixture$K5.3
K4 <- admixture$K5.4
K5 <- admixture$K5.5

admixdata5 <- data.frame(Lat,Long,K1,K2,K3,K4,K5)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata5, cols = c("K1", "K2", "K3", "K4", "K5")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()

# K = 6

Lat <- admixture$LATITUDE
Long <- admixture$LONGITUDE
K1 <- admixture$K1
K2 <- admixture$K2
K3 <- admixture$K3
K4 <- admixture$K4
K5 <- admixture$K5
K6 <- admixture$K6

admixdata6 <- data.frame(Lat,Long,K1,K2,K3,K4,K5,K6)

a + geom_scatterpie(aes(x = Long, y = Lat), data = admixdata6, cols = c("K1", "K2", "K3", "K4", "K5", "K6")) + scale_fill_manual(values=c("#F39C12", "#C39BD3", "#82E0AA", "#F7DC6F", "#EC7063", "#85C1E9")) + theme_light()
```

### =============================================== ###
### CALCULATING CLIMATE VARIABLES - RATE OF CHANGE  ###
### =============================================== ###

```First estimate slopes for change in each climate variable over time; separate file for each climate variable. yearJD - year jan-dec for winter variables. yearJJ - year july-june for summer variables. slopes based on 20 years of data prior to capture year. Removed year of capture as the amount of months each sample is exposed to in the year is variable (e.g. could be <1 if caught in January).```

```{r}
#### CHANGE IN MEAN TEMPERATURE ####

Change.Tmean <- read.csv("Tmean.ForChange.csv", header = T)
summary(Change.Tmean)

# these are missing from this data set:  "SAM9","SAM23", "SAM24", "SAM22", "SAM10", "SAM7"  
sample.list <- c("ANWC100","ANWC101","ANWC102","ANWC103","ANWC104","ANWC105","ANWC106","ANWC107","ANWC108","ANWC109","ANWC110","ANWC112","ANWC113","ANWC115","ANWC116",	"ANWC117","ANWC118","ANWC119","ANWC126","ANWC128","ANWC129","ANWC130","ANWC131","ANWC132","ANWC133","ANWC134","ANWC135","ANWC136","ANWC137","ANWC138","ANWC139","ANWC140","ANWC141","ANWC142","ANWC143","ANWC144","ANWC145","ANWC146","ANWC147","ANWC148","ANWC150","ANWC151","ANWC152","ANWC153","ANWC154","ANWC155","ANWC156","ANWC157","ANWC158","ANWC159","ANWC160","ANWC161","ANWC162","ANWC163","ANWC168","ANWC170","ANWC66","ANWC67","ANWC68","ANWC69","ANWC71","ANWC72","ANWC73","ANWC75","ANWC77","ANWC78","ANWC79","ANWC80","ANWC81","ANWC84","ANWC85","ANWC88","ANWC90","ANWC92","ANWC94","SAM11","SAM12","SAM14","SAM15","SAM16","SAM17","SAM18","SAM19","SAM20","SAM21","SAM25","SAM26","SAM27","SAM28","SAM29", "SAM30","SAM31","SAM32","SAM33","SAM34","SAM35","SAM36","SAM37","SAM38","SAM39","SAM41", "SAM44","SAM45","SAM46","SAM8","WAM55","WAM56","WAM57","WAM58","WAM59","WAM60","WAM63","WAM64")

names(sample.list) <- c("sample") # couldn't find object "sample" before

Model.sample <- data.frame()  # creates datafame fresh each time model is run, so don't add to previous file
for (sample in sample.list)                  #creates loop defined by curley brackets
{                       
  sample.m1 <- lm(Tmean ~ scale(YearJJ, scale=FALSE),  
                 data = subset(Change.Tmean, SAMPLE.ID==sample))
  #summary(sample.m1)
  sample.s1 <-cbind(sample, intercept = sample.m1$coefficients[1], coefYear = sample.m1$coefficients[2], 
                   df.residual = sample.m1$df.residual, adj.r.square = summary(sample.m1)$adj.r.squared, 
                   df = summary(sample.m1)$df[2], fstat = summary(sample.m1)$fstatistic[1], pvalue = summary(sample.m1)$coefficients[2,4])  
  Model.sample <-rbind(Model.sample, sample.s1)  # saves summary to file
}

rownames(Model.sample) <- 1:length(rownames(Model.sample))  # this overwrites the first column, and numbers rows sequentially 
write.csv(Model.sample,"ChangeMeanTemp.csv") 
```

```{r}
#### CHANGE IN NO. DAYS OVER 35 ####

Change.Ndays35<- read.csv("NDays35.ForChange.csv", header = T)
summary(Change.Ndays35)

# these are missing from this data set:  "SAM9","SAM23", "SAM24", "SAM22", "SAM10", "SAM7"  
sample.list <- c("ANWC100","ANWC101","ANWC102","ANWC103","ANWC104","ANWC105","ANWC106","ANWC107","ANWC108","ANWC109","ANWC110","ANWC112","ANWC113","ANWC115","ANWC116",	"ANWC117","ANWC118","ANWC119","ANWC126","ANWC128","ANWC129","ANWC130","ANWC131","ANWC132","ANWC133","ANWC134","ANWC135","ANWC136","ANWC137","ANWC138","ANWC139","ANWC140","ANWC141","ANWC142","ANWC143","ANWC144","ANWC145","ANWC146","ANWC147","ANWC148","ANWC150","ANWC151","ANWC152","ANWC153","ANWC154","ANWC155","ANWC156","ANWC157","ANWC158","ANWC159","ANWC160","ANWC161","ANWC162","ANWC163","ANWC168","ANWC170","ANWC66","ANWC67","ANWC68","ANWC69","ANWC71","ANWC72","ANWC73","ANWC75","ANWC77","ANWC78","ANWC79","ANWC80","ANWC81","ANWC84","ANWC85","ANWC88","ANWC90","ANWC92","ANWC94","SAM11","SAM12","SAM14","SAM15","SAM16","SAM17","SAM18","SAM19","SAM20","SAM21","SAM25","SAM26","SAM27","SAM28","SAM29", "SAM30","SAM31","SAM32","SAM33","SAM34","SAM35","SAM36","SAM37","SAM38","SAM39","SAM41", "SAM44","SAM45","SAM46","SAM8","WAM55","WAM56","WAM57","WAM58","WAM59","WAM60","WAM63","WAM64")

names(sample.list) <- c("sample") # couldn't find object "sample" before

Model.sample <- data.frame()  # creates datafame fresh each time model is run, so don't add to previous file
for (sample in sample.list)                  #creates loop defined by curley brackets
{                       
  sample.m1 <- lm(NDays35 ~ scale(YearJJ, scale=FALSE),  
                 data = subset(Change.Ndays35, SAMPLE.ID==sample))
  #summary(sample.m1)
  sample.s1 <-cbind(sample, intercept = sample.m1$coefficients[1], coefYear = sample.m1$coefficients[2], 
                   df.residual = sample.m1$df.residual, adj.r.square = summary(sample.m1)$adj.r.squared, 
                   df = summary(sample.m1)$df[2], fstat = summary(sample.m1)$fstatistic[1], pvalue = summary(sample.m1)$coefficients[2,4])  
  Model.sample <-rbind(Model.sample, sample.s1)  # saves summary to file
}

rownames(Model.sample) <- 1:length(rownames(Model.sample))  # this overwrites the first column, and numbers rows sequentially 
write.csv(Model.sample,"ChangeNdays35.csv")
```

```{r}
#### CHANGE IN NO. DAYS UNDER 5 ####

Change.Ndays5 <- read.csv("NDays5.ForChange.csv", header = T)
summary(Change.Ndays5)

# these are missing from this data set:  "SAM9","SAM23", "SAM24", "SAM22", "SAM10", "SAM7", "WAM55", "ANWC84", "ANWC85", "ANWC88", "ANWC90","ANWC92"
sample.list <- c("ANWC100","ANWC101","ANWC102","ANWC103","ANWC104","ANWC105","ANWC106","ANWC107","ANWC108","ANWC109","ANWC110","ANWC112","ANWC113","ANWC115","ANWC116",	"ANWC117","ANWC118","ANWC119","ANWC126","ANWC128","ANWC129","ANWC130","ANWC131","ANWC132","ANWC133","ANWC134","ANWC135","ANWC136","ANWC137", "ANWC138","ANWC139",	"ANWC140","ANWC141","ANWC142","ANWC143","ANWC144","ANWC145","ANWC146","ANWC147", "ANWC148","ANWC150","ANWC151","ANWC152","ANWC153","ANWC154","ANWC155","ANWC156","ANWC157", "ANWC158","ANWC159","ANWC160","ANWC161","ANWC162","ANWC163","ANWC168","ANWC170","ANWC66", "ANWC67", "ANWC68", "ANWC69", "ANWC71", "ANWC72", "ANWC73", "ANWC75", "ANWC77", "ANWC78","ANWC79", "ANWC80", "ANWC81", "ANWC94","SAM11", "SAM12", "SAM14", "SAM15", "SAM16", "SAM17", "SAM18", "SAM19", "SAM20", "SAM21","SAM25", "SAM26", "SAM27", "SAM28", "SAM29", "SAM30", "SAM31", "SAM32", "SAM33", "SAM34","SAM35", "SAM36", "SAM37", "SAM38", "SAM39", "SAM41", "SAM44", "SAM45", "SAM46", "SAM8", "WAM56", "WAM57", "WAM58", "WAM59", "WAM60", "WAM63", "WAM64")

names(sample.list) <- c("sample") # couldn't find object "sample" before

Model.sample <- data.frame()  # creates datafame fresh each time model is run, so don't add to previous file

for (sample in sample.list)                  #creates loop defined by curley brackets
{                       
  sample.m1 <- lm(Ndays5 ~ scale(YearJD, scale=FALSE),  
                 data = subset(Change.Ndays5, SAMPLE.ID==sample))
  #summary(sample.m1)
  sample.s1 <-cbind(sample, intercept = sample.m1$coefficients[1], coefYear = sample.m1$coefficients[2], 
                   df.residual = sample.m1$df.residual, adj.r.square = summary(sample.m1)$adj.r.squared, 
                   df = summary(sample.m1)$df[2], fstat = summary(sample.m1)$fstatistic[1], pvalue = summary(sample.m1)$coefficients[2,4])  
  Model.sample <-rbind(Model.sample, sample.s1)  # saves summary to file
}

rownames(Model.sample) <- 1:length(rownames(Model.sample))  # this overwrites the first column, and numbers rows sequentially
write.csv(Model.sample,"ChangeNdays5.csv")
```

```{r}
#### CHANGE IN PRECIPITATION ####

Change.Rain <- read.csv("Rain.ForChange.csv", header = T)
summary(Change.Rain)

# these are missing from this data set:  "SAM9","SAM23", "SAM24", "SAM22", "SAM10", "SAM7"  
sample.list <- c("ANWC100","ANWC101","ANWC102","ANWC103","ANWC104","ANWC105","ANWC106","ANWC107","ANWC108","ANWC109","ANWC110","ANWC112","ANWC113","ANWC115","ANWC116",	"ANWC117","ANWC118","ANWC119","ANWC126","ANWC128","ANWC129","ANWC130","ANWC131","ANWC132","ANWC133","ANWC134","ANWC135","ANWC136","ANWC137","ANWC138","ANWC139","ANWC140","ANWC141","ANWC142","ANWC143","ANWC144","ANWC145","ANWC146","ANWC147","ANWC148","ANWC150","ANWC151","ANWC152","ANWC153","ANWC154","ANWC155","ANWC156","ANWC157","ANWC158","ANWC159","ANWC160","ANWC161","ANWC162","ANWC163","ANWC168","ANWC170","ANWC66","ANWC67","ANWC68","ANWC69","ANWC71","ANWC72","ANWC73","ANWC75","ANWC77","ANWC78","ANWC79","ANWC80","ANWC81","ANWC84","ANWC85","ANWC88","ANWC90","ANWC92","ANWC94","SAM11","SAM12","SAM14","SAM15","SAM16","SAM17","SAM18","SAM19","SAM20","SAM21","SAM25","SAM26","SAM27","SAM28","SAM29", "SAM30","SAM31","SAM32","SAM33","SAM34","SAM35","SAM36","SAM37","SAM38","SAM39","SAM41", "SAM44","SAM45","SAM46","SAM8","WAM55","WAM56","WAM57","WAM58","WAM59","WAM60","WAM63","WAM64")

names(sample.list) <- c("sample") # couldn't find object "sample" before

Model.sample <- data.frame()  # creates datafame fresh each time model is run, so don't add to previous file
for (sample in sample.list)                  #creates loop defined by curley brackets
{                       
  sample.m1 <- lm(RainSum ~ scale(YearJD, scale=FALSE),  
                 data = subset(Change.Rain, SAMPLE.ID==sample))
  #summary(sample.m1)
  sample.s1 <-cbind(sample, intercept = sample.m1$coefficients[1], coefYear = sample.m1$coefficients[2], 
                   df.residual = sample.m1$df.residual, adj.r.square = summary(sample.m1)$adj.r.squared, 
                   df = summary(sample.m1)$df[2], fstat = summary(sample.m1)$fstatistic[1], pvalue = summary(sample.m1)$coefficients[2,4])  
  Model.sample <-rbind(Model.sample, sample.s1)  # saves summary to file
}

rownames(Model.sample) <- 1:length(rownames(Model.sample))  # this overwrites the first column, and numbers rows sequentially 
write.csv(Model.sample,"ChangeRain.csv")
```

```{r}
# Calculate the correlation matrix to test for correlations between the variables
# Import the data 
climate.corr <- read.csv("ElroyCorDataSummary.csv", header = T)

# Create the correlation matrix and write it into a new csv file
write.csv(cor(climate.corr[,2:17], use="pairwise.complete.obs"), "ElroyClimateCorMatrix.csv")
```

### ================================== ###
### DISTANCE MATRIX                    ###
### ================================== ###

```{r}

# how the distance matrix was calculated 
# load libraries
library(geosphere) # to create the distance matrix
library(readxl)

#load data
metadata <- read_excel("climate-metadata.xlsx")

longitude <- metadata$LONGITUDE
latitude <- metadata$LATITUDE
coord <- data.frame(longitude,latitude)
coordmatrix <- as.matrix(coord)
# calculate distance in metres using shortest distance between 
# 2 points method in geosphere package
distance <- distm(coordmatrix, fun=distGeo)
```

### ================================== ###
### MIXED MODELS: SPATIAL              ###
### ================================== ###

```{r}

library(readxl) 
library(ecodist)

# Load datasets

# CLIMATE DATA
# tropical + temperate individuals
climate.var <- read_excel("ClimVarMod.xlsx") 
# tropical + temperate individuals - no missing data
nmd.clim.var <- read_excel("ClimVarMod-NoMissingData.xlsx")
# temperate only individuals 
temp.climate.var <- read_excel("TemperateClimVarMod.xlsx")
# temperate only individuals - no missing data 
nmd.temp.climate.var <- read_excel("TemperateClimVarMod-NoMissingData.xlsx")

# GENETIC MATRIX
# tropical + temperate individuals 
genmatrix <- read.table("covariance-matrix.txt")
G <- as.matrix(genmatrix)
# tropical + temperate individuals - no missing data
nmd.genetic <- read.table("covariance-matrix-nmd.txt")
NG <- as.matrix(nmd.genetic)
# temperate only individuals
temp.genetic <- read.table("temperate-covariance-matrix.txt")
T.G <- as.matrix(temp.genetic)
# temperate only individuals - no missing data
nmd.temp.genetic <- read.table("covariance-matrix-nmd-temp.txt")
N.T.G <- as.matrix(nmd.temp.genetic)

# DISTANCE MATRIX
# tropical + temperate individuals
distance <- read.table("distance-matrix.txt")
D <- as.matrix(distance)
# tropical + temperate individuals - no missing data
nmd.distance <- read.table("distance-matrix-nmd.txt")
ND <- as.matrix(nmd.distance)
# temperate only individuals 
temp.distance <- read.table("temperate-distance-matrix.txt")
T.D <- as.matrix(temp.distance)
# temperate only individuals - no missing data
nmd.temp.distance <- read.table("distance-matrix-nmd-temp.txt")
N.T.D <- as.matrix(nmd.temp.distance)

# INBREEDING MODEL
# tropical + temperate
MRM(dist(INBREEDING) ~ as.dist(D) + as.dist(G) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=climate.var, nperm=500)

# tropical + temperate - no missing data 
MRM(dist(INBREEDING) ~ as.dist(ND) + as.dist(NG) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=nmd.clim.var, nperm=500)

# temperate only
MRM(dist(INBREEDING) ~ as.dist(T.D) + as.dist(T.G) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=temp.climate.var, nperm=500)

# GENETICS MODEL
# tropical + temperate
MRM(as.dist(G) ~ as.dist(D) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=climate.var, nperm=500)

# tropical + temperate - no missing data 
MRM(as.dist(NG) ~ as.dist(ND) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=nmd.clim.var, nperm=500)

# temperate only
MRM(as.dist(T.G) ~ as.dist(T.D) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=temp.climate.var, nperm=500)

# temperate only - no missing data 
MRM(as.dist(N.T.G) ~ as.dist(N.T.D) + dist(ScaledNdays35five) + dist(ScaledNdays5five) + dist(ScaledRainfive) + dist(Year), data=nmd.temp.climate.var, nperm=500)

```

### ================================== ###
### MIXED MODELS: TEMPORAL             ###
### ================================== ###

```{r}
# TEMPORAL INBREEDING MODEL
# load libraries 
library(sommer)
library(readxl)

# load datasets 
# these datasets have no missing data for any metadata or variables 
# CLIMATE DATA
# tropical + temperate
nmd.clim.var <- read_excel("ClimVarMod-NoMissingData.xlsx")
#temperate only
nmd.temp.clim.var <- read_excel("TemperateClimVarMod-NoMissingData.xlsx")

# GENETIC MATRIX 
# tropical + temperate 
nmd.matrix <- read.table("covariance-matrix-nmd.txt")
G <- as.matrix(nmd.matrix)
# temperate only
nmd.temp.matrix <- read.table("covariance-matrix-nmd-temp.txt")
T.G <- as.matrix(nmd.temp.matrix)

# MIXED MODEL IN SOMMER
# tropical + temperate - PRIMARY
inbreed.model <- mmer(fixed = INBREEDING ~ ScaledChangeMeanTemp * ScaledNdays35five + ScaledChangeMeanTemp * ScaledNdays5five + ScaledRainfive * ScaledChangeRain, random = ~ vs(ID, Gu=G) + Year + IBRA, rcov= ~ units, data=nmd.clim.var)

# tropical + temperate - COLD
inbreed.model2 <- mmer(fixed = INBREEDING ~ ScaledChangeMeanTemp * ScaledNdays5five + ScaledRainfive * ScaledChangeRain, random = ~ vs(ID, Gu=G) + Year + IBRA, rcov= ~ units, data=nmd.clim.var)

# tropical + temperate - HOT
inbreed.model3 <- mmer(fixed = INBREEDING ~ ScaledChangeMeanTemp * ScaledNdays35five + ScaledRainfive * ScaledChangeRain, random = ~ vs(ID, Gu=G) + Year + IBRA, rcov= ~ units, data=nmd.clim.var)
```

```{r}

# TEMPORAL GENETICS MODEL

library(vegan)
library(readxl)

# load datasets 
# these datasets have no missing data for any metadata or variables 
# CLIMATE DATA
# tropical + temperate
nmd.clim.var <- read_excel("ClimVarMod-NoMissingData.xlsx")
#temperate only
nmd.temp.clim.var <- read_excel("TemperateClimVarMod-NoMissingData.xlsx")

# GENETIC MATRIX 
# tropical + temperate 
nmd.matrix <- read.table("covariance-matrix-nmd.txt")
G <- as.matrix(nmd.matrix)
AG <- as.matrix(G)
# convert any negative values to a zero as adonis2 doesn't like negatives 
AG[AG < 0] <- 0
# temperate only
nmd.temp.matrix <- read.table("covariance-matrix-nmd-temp.txt")
T.G <- as.matrix(nmd.temp.matrix)

# MIXED MODEL USING ADONIS 
# tropical + temperate 
temporal.model1 <- adonis2(AG ~ ScaledChangeMeanTemp*ScaledNdays35five + ScaledChangeMeanTemp*ScaledNdays5five + ScaledRainfive*ScaledChangeRain + Year + IBRA, data = nmd.clim.var)

temporal.model2 <- adonis2(AG ~ ScaledChangeMeanTemp*ScaledNdays35five + ScaledRainfive*ScaledChangeRain + Year + IBRA, data = nmd.clim.var)

temporal.model3 <- adonis2(AG ~ ScaledChangeMeanTemp*ScaledNdays5five + ScaledRainfive*ScaledChangeRain + Year + IBRA, data = nmd.clim.var)

# Calculate AICs for adonis models 
# Script source: https://github.com/kdyson/R_Scripts/blob/master/AICc_PERMANOVA.R

AICc.PERMANOVA2 <- function(adonis2.model) {
     
     # check to see if object is an adonis2 model...
     
     if (is.na(adonis2.model$SumOfSqs[1]))
         stop("object not output of adonis2 {vegan} ")
     
     # Ok, now extract appropriate terms from the adonis model Calculating AICc
     # using residual sum of squares (RSS or SSE) since I don't think that adonis
     # returns something I can use as a liklihood function... o wait maximum likelihood may be MSE.
     
     RSS <- adonis2.model$SumOfSqs[ length(adonis2.model$SumOfSqs) - 1 ]
     MSE <- RSS / adonis2.model$Df[ length(adonis2.model$Df) - 1 ]
     
     nn <- adonis2.model$Df[ length(adonis2.model$Df) ] + 1
     
     k <- nn - adonis2.model$Df[ length(adonis2.model$Df) - 1 ]
     
     
     # AIC : 2*k + n*ln(RSS)
     # AICc: AIC + [2k(k+1)]/(n-k-1)
     
     # based on https://en.wikipedia.org/wiki/Akaike_information_criterion;
     # https://www.researchgate.net/post/What_is_the_AIC_formula;
     # http://avesbiodiv.mncn.csic.es/estadistica/ejemploaic.pdf
     
     # AIC.g is generalized version of AIC = 2k + n [Ln( 2(pi) RSS/n ) + 1]
     # AIC.pi = k + n [Ln( 2(pi) RSS/(n-k) ) +1],
     
     AIC <- 2*k + nn*log(RSS)
     AIC.g <- 2*k + nn * (1 + log( 2 * pi * RSS / nn))
     AIC.MSE <- 2*k + nn * log(MSE)
     AIC.pi <- k + nn*(1 + log( 2*pi*RSS/(nn-k) )   )
     AICc <- AIC + (2*k*(k + 1))/(nn - k - 1)
     AICc.MSE <- AIC.MSE + (2*k*(k + 1))/(nn - k - 1)
     AICc.pi <- AIC.pi + (2*k*(k + 1))/(nn - k - 1)
     
     output <- list("AIC" = AIC, "AIC.g" = AIC.g, "AICc" = AICc,
                    "AIC.MSE" = AIC.MSE, "AICc.MSE" = AICc.MSE,
                    "AIC.pi" = AIC.pi, "AICc.pi" = AICc.pi, "k" = k)
     
     return(output)   
     
}

AICc.PERMANOVA2(adonis2.model = temporal.model1)
AICc.PERMANOVA2(adonis2.model = temporal.model2)
AICc.PERMANOVA2(adonis2.model = temporal.model3)
```

### ================================== ###
### CORRELATION COEFFICIENTS           ###
### ================================== ###

```{r}

# Calculate correlation coefficients to tell directions of trends
# Load datasets 
distance <- read.table("distance-matrix.txt")
D <- as.matrix(distance)
nmd.distance <- read.table("distance-matrix-nmd.txt")
ND <- as.matrix(nmd.distance)
nmd.genetic <- read.table("covariance-matrix-nmd.txt")
NG <- as.matrix(nmd.genetic)
nmd.clim.var <- read_excel("ClimVarMod-NoMissingData.xlsx")
# remove zeroes in covariance matrix, like for adonis 
NG2 <- as.matrix(nmd.genetic)
NG2[NG2 < 0] <- 0

# Load variables as distance based
covariance <- as.numeric(as.dist(NG))
distance <- as.numeric(as.dist(ND))
year <- as.numeric (dist(nmd.clim.var$Year))
mean.temp <- as.numeric(dist(nmd.clim.var$ScaledChangeMeanTemp))
rain <- as.numeric(dist(nmd.clim.var$ScaledChangeRain))
ndasy35 <- as.numeric(dist(nmd.clim.var$ScaledNdays35five))
ndasy5 <- as.numeric(dist(nmd.clim.var$ScaledNdays5five))
covariance.zero <- as.numeric(as.dist(NG2))
mean.temp.35 <- mean.temp * ndasy35
mean.temp.5 <- mean.temp * ndasy5
rain.change <- as.numeric(dist(nmd.clim.var$ScaledChangeRain))
rain <- as.numeric(dist(nmd.clim.var$ScaledRainfive))
rain.change.rain <- rain.change * rain

# calculate pearson's correlation co-efficients
cor.test(covariance.zero, year, method=c("pearson"))
cor.test(covariance.zero, mean.temp.35, method=c("pearson"))
cor.test(covariance.zero, mean.temp, method=c("pearson"))
cor.test(covariance.zero, ndasy35, method=c("pearson"))
cor.test(covariance.zero, ndasy5, method=c("pearson"))
cor.test(covariance.zero, mean.temp.5, method=c("pearson"))
cor.test(covariance.zero, rain.change, method=c("pearson"))
cor.test(covariance.zero, rain, method=c("pearson"))
cor.test(covariance.zero, rain.change.rain, method=c("pearson"))
```

### ================================== ###
### MIXED MODELS: GRAPHS               ###
### ================================== ###

```{r}

# Load libraries 
library(ggplot2)
library(readxl)

# Load datasets
distance <- read.table("distance-matrix.txt")
D <- as.matrix(distance)
genmatrix <- read.table("covariance-matrix.txt")
G <- as.matrix(genmatrix)
climate.var <- read_excel("ClimVarMod.xlsx")
          
# Create the dataframe for the hexplots 
covariance <- as.numeric(as.dist(G))
distance <- as.numeric(as.dist(D))
year <- as.numeric (dist(climate.var$Year))
rain <- as.numeric(dist(climate.var$ScaledChangeRain))
mean.temp <- as.numeric(dist(climate.var$ScaledChangeMeanTemp))
hex.data <- data.frame(year, covariance, rain, mean.temp, distance)

# Plot
# Genetic covariance and pairwise temporal distance between samples 
ggplot(hex.data, aes(covariance, year)) + geom_hex() + labs(x = "Genetic Covariance", y = "Age Difference (Years)") + theme_bw()

# Genetic covariance and pairwsie spatial distance between samples 
ggplot(hex.data, aes(covariance, distance)) + geom_hex() + labs(x = "Genetic Covariance", y = "Distance between Individuals (m)") + theme_bw()

# Genetic covariance and pairwise difference in rate of mean temperature 
# change 
ggplot(hex.data, aes(covariance, mean.temp)) + geom_hex() + labs(x = "Genetic Covariance", y = "Difference in Rate of Mean Temperature Change (°C)") + theme_bw()

# Genetic covariance and pairwise difference in rate of change in annual 
# rainfall
ggplot(hex.data, aes(covariance, rain)) + geom_hex() + labs(x = "Genetic Covariance", y = "Difference in Rate of Annual Rainfall (mm)") + theme_bw()
```